{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9b5534",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Basic setup and imports\n",
    "# main_experiments.ipynb\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make plots a bit nicer\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ee575f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Make src/ importable and import models\n",
    "# Locate repo root and add src/ to Python path\n",
    "root = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "src_dir = root / \"src\"\n",
    "sys.path.append(str(src_dir))\n",
    "\n",
    "print(\"Repo root:\", root)\n",
    "print(\"src dir:\", src_dir)\n",
    "\n",
    "from models import build_resnet50_base, build_resnet50_modified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104bfc26",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Data paths and dataset loading\n",
    "# Point to the processed HAM10000 data directory\n",
    "DATA_ROOT = root / \"data_ham10000\"  # change to \"data\" if that's what you used\n",
    "\n",
    "train_dir = DATA_ROOT / \"train\"\n",
    "val_dir   = DATA_ROOT / \"val\"\n",
    "test_dir  = DATA_ROOT / \"test\"\n",
    "\n",
    "print(\"Train dir:\", train_dir)\n",
    "print(\"Val dir:\", val_dir)\n",
    "print(\"Test dir:\", test_dir)\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "SEED = 42\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "print(\"Classes:\", class_names, \" | num_classes =\", num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6b717e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Preetch and basic normalization\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def configure_ds(ds, shuffle=False):\n",
    "    ds = ds.map(lambda x, y: (tf.cast(x, tf.float32) / 255.0, y),\n",
    "                num_parallel_calls=AUTOTUNE)\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(1000)\n",
    "    return ds.prefetch(AUTOTUNE)\n",
    "\n",
    "train_ds_prep = configure_ds(train_ds, shuffle=True)\n",
    "val_ds_prep   = configure_ds(val_ds, shuffle=False)\n",
    "test_ds_prep  = configure_ds(test_ds, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aa1f85",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Build both models and give a summary\n",
    "\n",
    "# Build baseline and modified models\n",
    "resnet50_base = build_resnet50_base(num_classes=num_classes)\n",
    "resnet50_mod  = build_resnet50_modified(num_classes=num_classes)\n",
    "\n",
    "resnet50_base.summary()\n",
    "resnet50_mod.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1f8794",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Compile both models\n",
    "loss_fn = keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "resnet50_base.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=loss_fn,\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n",
    "resnet50_mod.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=loss_fn,\n",
    "    metrics=metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ab1940",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Callbacks to save the best models\n",
    "\n",
    "models_dir = root / \"models\"\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "base_ckpt_path = models_dir / \"best_resnet50_base.keras\"\n",
    "mod_ckpt_path  = models_dir / \"best_resnet50_modified.keras\"\n",
    "\n",
    "checkpoint_base = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=str(base_ckpt_path),\n",
    "    monitor=\"val_accuracy\",\n",
    "    save_best_only=True,\n",
    "    mode=\"max\",\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "checkpoint_mod = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=str(mod_ckpt_path),\n",
    "    monitor=\"val_accuracy\",\n",
    "    save_best_only=True,\n",
    "    mode=\"max\",\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    patience=5,\n",
    "    mode=\"max\",\n",
    "    restore_best_weights=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03e89a6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Train baseline ResNet50 \n",
    "\n",
    "EPOCHS = 15\n",
    "\n",
    "history_base = resnet50_base.fit(\n",
    "    train_ds_prep,\n",
    "    validation_data=val_ds_prep,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[checkpoint_base, early_stop],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08e854c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Train modified ResNet50 with suppression-and-excitement\n",
    "\n",
    "# You can reuse early_stop, or re-create a separate one if you want different patience\n",
    "early_stop_mod = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    patience=5,\n",
    "    mode=\"max\",\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history_mod = resnet50_mod.fit(\n",
    "    train_ds_prep,\n",
    "    validation_data=val_ds_prep,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[checkpoint_mod, early_stop_mod],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ca5e4f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Find and save Confusion Matrix\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "figures_dir = root / \"figures\"\n",
    "figures_dir.mkdir(exist_ok=True)\n",
    "\n",
    "def save_confusion_matrix(model, dataset, class_names, output_path):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for batch_images, batch_labels in dataset:\n",
    "        preds = model.predict(batch_images, verbose=0)\n",
    "        pred_classes = np.argmax(preds, axis=1)\n",
    "\n",
    "        # if labels are one-hot\n",
    "        if batch_labels.ndim > 1 and batch_labels.shape[-1] == len(class_names):\n",
    "            true_classes = np.argmax(batch_labels, axis=1)\n",
    "        else:\n",
    "            true_classes = batch_labels.numpy()\n",
    "\n",
    "        y_true.extend(true_classes)\n",
    "        y_pred.extend(pred_classes)\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(\"Confusion matrix (raw):\\n\", cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(ax=ax, values_format=\"d\", xticks_rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9043f64d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Evaluate on test set and save confusion matricies\n",
    "import time\n",
    "\n",
    "# Evaluate baseline\n",
    "print(\"Baseline ResNet50 on test set: \")\n",
    "base_start = time.time()\n",
    "test_loss_base, test_acc_base = resnet50_base.evaluate(test_ds_prep)\n",
    "base_end = int(time.time() - base_start)\n",
    "print(f\"Test accuracy (base): {test_acc_base:.4f}\")\n",
    "print(f\"Total training time: {base_end}\")\n",
    "\n",
    "# Evaluate modified\n",
    "print(\"Modified ResNet50 + SE on test set: \")\n",
    "mod_start = time.time()\n",
    "test_loss_mod, test_acc_mod = resnet50_mod.evaluate(test_ds_prep)\n",
    "mod_end = int(time.time() - mod_start)\n",
    "print(f\"Test accuracy (modified): {test_acc_mod:.4f}\")\n",
    "print(f\"Total training time: {mod_end}\")\n",
    "\n",
    "# Save confusion matrices\n",
    "cm_base_path = figures_dir / \"confusion_matrix_resnet50_base.png\"\n",
    "cm_mod_path  = figures_dir / \"confusion_matrix_resnet50_modified.png\"\n",
    "\n",
    "save_confusion_matrix(resnet50_base, test_ds_prep, class_names, cm_base_path)\n",
    "save_confusion_matrix(resnet50_mod,  test_ds_prep, class_names, cm_mod_path)\n",
    "\n",
    "print(\"Saved confusion matrices to:\")\n",
    "print(\"  \", cm_base_path)\n",
    "print(\"  \", cm_mod_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7632c4b5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Plot the training curves\n",
    "\n",
    "def plot_history(history, title, output_path):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "    plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "#Training curves path\n",
    "train_base_path = figures_dir / \"training_curves_resnet50_base.png\"\n",
    "train_mod_path = figures_dir / \"training_curves_resnet50_modified.png\"\n",
    "\n",
    "plot_history(history_base, \"Baseline ResNet50\", train_base_path)\n",
    "plot_history(history_mod, \"Modified ResNet50 + SE\", train_mod_path)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
